{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ETKSGEGU_EYU"
      },
      "outputs": [],
      "source": [
        "#importing modules\n",
        "import os\n",
        "import codecs\n",
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import tarfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jGq78nAZr9ND"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4e2pi7u6CH39"
      },
      "outputs": [],
      "source": [
        "#downloading and extracting the files on colab server\n",
        "tar = tarfile.open(\"/Users/redap/Documents/GitHub/CS481/20_newsgroups.tar\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "4k_0llvo_EYX",
        "outputId": "22bad58e-b34a-43d9-b6e5-d2d0d9a812b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19997"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#making a list of all the file paths and their corresponding class\n",
        "f_paths=[]\n",
        "i=-1\n",
        "path=\"20_newsgroups\"\n",
        "folderlist=os.listdir(path)\n",
        "if \".DS_Store\" in folderlist:\n",
        "  folderlist.remove('.DS_Store')\n",
        "for folder in folderlist:\n",
        "  i+=1\n",
        "  filelist=os.listdir(path+'/'+folder)\n",
        "  for file in filelist:\n",
        "    f_paths.append((path+'/'+folder+'/'+file,i))\n",
        "len(f_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "fU1RzKP1yyPp",
        "outputId": "c0975a57-4f16-4d5b-bf67-7d72f3b8ba7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14997, 5000)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#splitting the list of paths into training and testing data\n",
        "from sklearn import model_selection\n",
        "x_train,x_test=model_selection.train_test_split(f_paths)\n",
        "len(x_train),len(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "O_8VmW_fzvO5",
        "outputId": "5beb67da-20f7-4f7a-f4bf-d9e3ed5739c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14997,), (5000,))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Making the lists X_train and X_test containg only the paths of the files in training and testing data\n",
        "#First making lists Y_train and Y_test containing the classes of the training and testing data\n",
        "X_train=[]\n",
        "X_test=[]\n",
        "Y_train=[]\n",
        "Y_test=[]\n",
        "for i in range(len(x_train)):\n",
        "  X_train.append(x_train[i][0])\n",
        "  Y_train.append(x_train[i][1])\n",
        "for i in range(len(x_test)):\n",
        "  X_test.append(x_test[i][0])\n",
        "  Y_test.append(x_test[i][1])\n",
        "#Transforming Y_train and Y_test into 1 dimensional np arrays\n",
        "Y_train=(np.array([Y_train])).reshape(-1)\n",
        "Y_test=(np.array([Y_test])).reshape(-1)\n",
        "#shape of Y_train and Y_test np arrays\n",
        "Y_train.shape,Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "D4sbNla-Zjf-",
        "outputId": "49dc2099-d159-446d-f8bd-1bdbfdbd916b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/redap/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "I1IWj03cZcz9",
        "outputId": "28cafc7d-37c1-4eac-8bba-cba8fb478fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "211"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#adding all the above lists and including punctuations to stop words\n",
        "stop_words=list(stop)+list(set(string.punctuation))\n",
        "len(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rxf9J4g4_EYf"
      },
      "outputs": [],
      "source": [
        "#making vocabulary from the files in X_train i.e. training data\n",
        "vocab={}\n",
        "count =0\n",
        "for filename in X_train:\n",
        "  count+=1\n",
        "  f = open(filename,'r',errors='ignore')\n",
        "  record=f.read()\n",
        "  words=record.split()\n",
        "  for word in words:\n",
        "    if len(word)>2:\n",
        "      if word.lower() not in stop_words:\n",
        "        if word.lower() in vocab:\n",
        "          vocab[word.lower()]+=1\n",
        "        else:\n",
        "          vocab[word.lower()]=1\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "rl5HJz0-_EYk",
        "outputId": "aeab1391-fe2a-475f-8bbf-aba0943b9910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "353458"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#length of the vocabulary\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "w0G8_FDc_EYn"
      },
      "outputs": [],
      "source": [
        "#sorting the vocabulary on the basis of the frequency of the word\n",
        "#making the sorted vocabulary\n",
        "import operator\n",
        "sorted_vocab = sorted(vocab.items(), key= operator.itemgetter(1), reverse= True)   # sort the vocab based on frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AoK5V6zY_EYo"
      },
      "outputs": [],
      "source": [
        "#making the list feature_names containg the words with the frequency of the top 2000 words\n",
        "feature_names = []\n",
        "for i in range(len(sorted_vocab)):\n",
        "    if(sorted_vocab[2000][1] <= sorted_vocab[i][1]):\n",
        "        feature_names.append(sorted_vocab[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "iUuVWVOO_EYr",
        "outputId": "bcdaef8d-6962-4381-c647-9ca110191733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2012\n"
          ]
        }
      ],
      "source": [
        "#length of the feature_names i.e. number of our features\n",
        "print(len(feature_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5LvFD1r8_EYt"
      },
      "outputs": [],
      "source": [
        "#making dataframes df_train and df_test with columns having the feature names i.e. the words\n",
        "df_train=pd.DataFrame(columns=feature_names)\n",
        "df_test=pd.DataFrame(columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "v5GbdNAY_EYw",
        "outputId": "831eefb5-e743-4bfd-8153-0cd8367c93ee"
      },
      "outputs": [],
      "source": [
        "count_train,count_test=0,0\n",
        "\n",
        "#transforming each file in X_train into a row in the dataframe df_train having columns as feature names and values as the frequency of that feature name i.e that word\n",
        "for filename in X_train:\n",
        "  count_train+=1\n",
        "  #adding a row of zeros for each file\n",
        "  df_train.loc[len(df_train)]=np.zeros(len(feature_names))\n",
        "  f = open(filename,'r',errors='ignore')\n",
        "  record=f.read()\n",
        "  words=record.split()\n",
        "  #parsing through all the words of the file\n",
        "  for word in words:\n",
        "    if word.lower() in df_train.columns:\n",
        "      df_train[word.lower()][len(df_train)-1]+=1 #if the word is in the column names then adding 1 to the frequency of that word in the row\n",
        "  f.close()\n",
        "  \n",
        "#transforming each file in X_test into a row in the dataframe df_test having columns as feature names and values as the frequency of that feature name i.e that word  \n",
        "for filename in X_test:\n",
        "  count_test+=1\n",
        "  #adding a row of zeros for each file\n",
        "  df_test.loc[len(df_test)]=np.zeros(len(feature_names))\n",
        "  f = open(filename,'r',errors='ignore')\n",
        "  record=f.read()\n",
        "  words=record.split()\n",
        "  #parsing through all the words of the file\n",
        "  for word in words:\n",
        "    if word.lower() in df_test.columns:\n",
        "      df_test[word.lower()][len(df_test)-1]+=1 #if the word is in the column names then adding 1 to the frequency of that word in the row\n",
        "  f.close()\n",
        "  \n",
        "#printing the number files tranformed in training and testing data\n",
        "print(count_train,count_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "u2LneYsIdbyy"
      },
      "outputs": [],
      "source": [
        "#putting the values of the datafames into X_train and X_test\n",
        "X_train=df_train.values\n",
        "X_test=df_test.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nFKQk-p_pLUl"
      },
      "source": [
        "# **Using the inbuilt Multinomial Naive Bayes classifier from sklearn**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "colab_type": "code",
        "id": "TMX2648a_EYz",
        "outputId": "00ef1c1d-bb7e-4b09-b928-ac48062288cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.77      0.85       245\n",
            "           1       0.78      0.91      0.84       255\n",
            "           2       0.93      0.91      0.92       233\n",
            "           3       0.71      0.80      0.75       263\n",
            "           4       0.94      0.95      0.95       253\n",
            "           5       0.83      0.80      0.81       244\n",
            "           6       0.97      0.97      0.97       280\n",
            "           7       0.95      0.84      0.90       269\n",
            "           8       0.90      0.87      0.88       251\n",
            "           9       0.67      0.60      0.63       246\n",
            "          10       0.84      0.92      0.88       267\n",
            "          11       0.89      0.89      0.89       236\n",
            "          12       0.82      0.77      0.79       217\n",
            "          13       0.88      0.83      0.85       273\n",
            "          14       0.70      0.87      0.78       220\n",
            "          15       0.74      0.87      0.80       239\n",
            "          16       0.92      0.80      0.85       242\n",
            "          17       0.95      0.99      0.97       260\n",
            "          18       0.74      0.87      0.80       262\n",
            "          19       0.63      0.42      0.51       245\n",
            "\n",
            "    accuracy                           0.84      5000\n",
            "   macro avg       0.84      0.83      0.83      5000\n",
            "weighted avg       0.84      0.84      0.83      5000\n",
            "\n",
            "Testing:  0.8354\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "clf=MultinomialNB()\n",
        "#fitting the classifier on training data\n",
        "clf.fit(X_train,Y_train)\n",
        "#prediciting the classes of the testing data\n",
        "Y_pred=clf.predict(X_test)\n",
        "#classification report\n",
        "print(classification_report(Y_test,Y_pred))\n",
        "#testing score\n",
        "print(\"Testing: \",clf.score(X_test,Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "from joblib import dump\n",
        "\n",
        "model_dir = '/Users/redap/Documents/GitHub/CS481' \n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "model_path = os.path.join(model_dir, 'multinomial_nb_model.joblib')\n",
        "dump(clf, model_path)\n",
        "\n",
        "print(os.path.exists(model_path)) \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Text_Classification_project.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
